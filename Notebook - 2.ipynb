{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# FutureWarning ile ilgili ayar\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# 1. Dosyaları yükle\n",
        "train_df = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\train.csv\", low_memory=False)\n",
        "test_df = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\test_x.csv\", low_memory=False)\n",
        "submission_sample = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\sample_submission.csv\", low_memory=False)\n",
        "\n",
        "# 2. Eksik değerlerin analizi ve doldurulması\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
        "numerical_cols = train_df.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "# Sayısal sütunlardaki eksik değerleri ortalama ile dolduralım\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "train_df[numerical_cols] = imputer_num.fit_transform(train_df[numerical_cols])\n",
        "\n",
        "# Kategorik sütunlardaki eksik değerleri en sık görülen değer (mod) ile dolduralım\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "train_df[categorical_cols] = imputer_cat.fit_transform(train_df[categorical_cols])\n",
        "\n",
        "# 3. Target Encoding uygulayalım\n",
        "target_encoder = TargetEncoder()\n",
        "train_df[categorical_cols] = target_encoder.fit_transform(train_df[categorical_cols], train_df['Degerlendirme Puani'])\n",
        "\n",
        "# Aynı işlemi test verisi için de uygulayalım\n",
        "test_df[categorical_cols] = target_encoder.transform(test_df[categorical_cols])\n",
        "\n",
        "# 4. Aykırı değerlerin analizi ve filtrelenmesi (IQR yöntemi ile)\n",
        "for col in numerical_cols:\n",
        "    Q1 = train_df[col].quantile(0.25)\n",
        "    Q3 = train_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    train_df = train_df[(train_df[col] >= lower_bound) & (train_df[col] <= upper_bound)]\n",
        "\n",
        "# 5. Hedef ve özellikleri belirleyelim\n",
        "X = train_df.drop(columns=['Degerlendirme Puani'])\n",
        "y = train_df['Degerlendirme Puani']\n",
        "\n",
        "# Eğitim ve doğrulama setlerine ayıralım\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Recursive Feature Elimination (RFE) ile özellik seçimi yapalım\n",
        "rfe_selector = RFE(estimator=RandomForestRegressor(random_state=42), n_features_to_select=10, step=1)\n",
        "rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# Seçilen özellikler\n",
        "X_train_rfe = X_train.loc[:, rfe_selector.support_]\n",
        "X_valid_rfe = X_valid.loc[:, rfe_selector.support_]\n",
        "\n",
        "# 7. Hiperparametre optimizasyonu - RandomForest için\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [10, 20, 30, 40, None],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                           param_grid=param_grid_rf,\n",
        "                           cv=5,\n",
        "                           n_jobs=-1,\n",
        "                           verbose=2)\n",
        "grid_search_rf.fit(X_train_rfe, y_train)\n",
        "\n",
        "# En iyi RandomForest parametreleri\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "print(\"En iyi RandomForest parametreleri:\", best_params_rf)\n",
        "\n",
        "# RandomForest ile en iyi modelle eğitim\n",
        "best_model_rf = RandomForestRegressor(**best_params_rf, random_state=42)\n",
        "best_model_rf.fit(X_train_rfe, y_train)\n",
        "\n",
        "# Doğrulama setinde tahmin yapalım\n",
        "y_pred_rf = best_model_rf.predict(X_valid_rfe)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_valid, y_pred_rf))\n",
        "print(\"\\nRandomForest Modeli Validation RMSE:\", rmse_rf)\n",
        "\n",
        "# 8. Hiperparametre optimizasyonu - XGBoost için\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search_xgb = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "                               param_grid=param_grid_xgb,\n",
        "                               cv=5,\n",
        "                               n_jobs=-1,\n",
        "                               verbose=2)\n",
        "grid_search_xgb.fit(X_train_rfe, y_train)\n",
        "\n",
        "# En iyi XGBoost parametreleri\n",
        "best_params_xgb = grid_search_xgb.best_params_\n",
        "print(\"En iyi XGBoost parametreleri:\", best_params_xgb)\n",
        "\n",
        "# XGBoost ile en iyi modelle eğitim\n",
        "xgb_best_model = xgb.XGBRegressor(**best_params_xgb)\n",
        "xgb_best_model.fit(X_train_rfe, y_train)\n",
        "\n",
        "# Doğrulama setinde tahmin yapalım\n",
        "y_pred_xgb = xgb_best_model.predict(X_valid_rfe)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_valid, y_pred_xgb))\n",
        "print(\"\\nXGBoost Modeli Validation RMSE:\", rmse_xgb)\n",
        "\n",
        "# 9. Stratified K-Fold CV ile XGBoost\n",
        "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_search_xgb_cv = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "                                  param_grid=param_grid_xgb,\n",
        "                                  cv=strat_kfold,\n",
        "                                  n_jobs=-1,\n",
        "                                  verbose=2)\n",
        "grid_search_xgb_cv.fit(X_train_rfe, y_train)\n",
        "\n",
        "# En iyi modelin tahmini\n",
        "y_pred_xgb_cv = grid_search_xgb_cv.predict(X_valid_rfe)\n",
        "rmse_xgb_cv = np.sqrt(mean_squared_error(y_valid, y_pred_xgb_cv))\n",
        "print(\"\\nStratified K-Fold ile XGBoost Modeli Validation RMSE:\", rmse_xgb_cv)\n",
        "\n",
        "# 10. Ensemble modeli (RandomForest ve XGBoost)\n",
        "ensemble_predictions = (best_model_rf.predict(X_valid_rfe) + xgb_best_model.predict(X_valid_rfe)) / 2\n",
        "rmse_ensemble = np.sqrt(mean_squared_error(y_valid, ensemble_predictions))\n",
        "print(\"\\nEnsemble Modeli Validation RMSE:\", rmse_ensemble)\n",
        "\n",
        "# 11. Test verisi üzerinde tahmin yapalım\n",
        "test_df[numerical_cols] = imputer_num.transform(test_df[numerical_cols])\n",
        "test_predictions_ensemble = (best_model_rf.predict(test_df) + xgb_best_model.predict(test_df)) / 2\n",
        "\n",
        "# Submission dosyası\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'Degerlendirme Puani': test_predictions_ensemble\n",
        "})\n",
        "\n",
        "submission.to_csv(r\"C:\\Users\\Admin\\Desktop\\submission_ensemble.csv\", index=False)\n",
        "print(\"Ensemble submission dosyası oluşturuldu.\")\n",
        "\n",
        "# 12. Exploratory Data Analysis (EDA)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(y, kde=True)\n",
        "plt.title('Degerlendirme Puani Dağılımı')\n",
        "plt.xlabel('Degerlendirme Puani')\n",
        "plt.ylabel('Frekans')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr = train_df.corr()\n",
        "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
        "plt.title('Özellikler Arası Korelasyon Matrisi')\n",
        "plt.show()\n",
        "\n",
        "residuals_ensemble = y_valid - ensemble_predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals_ensemble, kde=True)\n",
        "plt.title('Ensemble Modeli Hata Dağılımı')\n",
        "plt.xlabel('Hata Değeri')\n",
        "plt.ylabel('Frekans')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
